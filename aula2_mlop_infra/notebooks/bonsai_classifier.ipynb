{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd3bb5bb",
   "metadata": {},
   "source": [
    "## MLflow 3.3.1 Best Practices and MLOps Workflow\n",
    "\n",
    "This notebook demonstrates a complete MLOps workflow using MLflow 3.3.1, including:\n",
    "\n",
    "- **Experiment Tracking:** Logging parameters, metrics, and artifacts (confusion matrix, predictions CSV) for reproducibility.\n",
    "- **Model Registry:** Registering models, managing lifecycle stages (Staging, Production), and promoting models when approved.\n",
    "- **Artifact Logging:** Ensuring all relevant outputs are saved for future analysis and auditability.\n",
    "- **Automation:** GitHub Actions for notebook cleaning and dependency updates to maintain code quality and security.\n",
    "\n",
    "The workflow is designed for educational clarity, following best practices for experiment management, model versioning, and CI/CD automation in MLOps projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0a242-4f18-4bf0-8013-fa04e9337838",
   "metadata": {},
   "source": [
    "# Class II: Infrastructure as Code for MLOps\n",
    "\n",
    "## üå± Project: Bonsai Species Classifier for Plant E-commerce\n",
    "\n",
    "Welcome to our hands-on MLOps session! We're building a **bonsai species classifier** for a plant website that will:\n",
    "- **Identify bonsai species** from plant measurements\n",
    "- **Provide care recommendations** based on species type\n",
    "- **Help customers** choose the right bonsai for their needs\n",
    "\n",
    "### Infrastructure Stack (All Containerized!)\n",
    "- **MLflow**: For experiment tracking and model registry\n",
    "- **Docker**: All services are containerized (no local installation needed!)\n",
    "- **JupyterLab**: You're running this from a container right now\n",
    "- **API**: Model serving for the plant website\n",
    "\n",
    "## Quick Setup Check\n",
    "Make sure all containers are running:\n",
    "- MLflow UI: http://localhost:5001 (track bonsai model experiments)\n",
    "- JupyterLab: http://localhost:8888 (you're here!)\n",
    "- API: http://localhost:8080 (bonsai species prediction service)\n",
    "\n",
    "Let's start building our bonsai classifier! üå≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752f67cc-54cf-40f2-afe7-387993031cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow already installed\n",
      "üéØ MLflow Tracking URI: http://mlflow:5000\n",
      "üöÄ Ready to track experiments!\n"
     ]
    }
   ],
   "source": [
    "# First, let's install MLflow in this container and set up the connection\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install MLflow if not already installed\n",
    "try:\n",
    "    import mlflow\n",
    "    print(\"‚úÖ MLflow already installed\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing MLflow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"mlflow==3.3.1\"])\n",
    "    import mlflow\n",
    "\n",
    "# Set the MLflow tracking URI to connect to our containerized MLflow server\n",
    "import os\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'http://mlflow:5000'\n",
    "mlflow.set_tracking_uri('http://mlflow:5000')\n",
    "\n",
    "print(f\"üéØ MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(\"üöÄ Ready to track experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab780523-a468-4879-8f2d-c50abd911569",
   "metadata": {},
   "source": [
    "# üå≥ Bonsai Species Classification with MLflow\n",
    "\n",
    "Now let's train our bonsai species classifier and track the experiment. We'll classify 4 types of bonsai:\n",
    "- **Juniper Bonsai** (0): Hardy, needle-like foliage\n",
    "- **Ficus Bonsai** (1): Broad leaves, aerial roots  \n",
    "- **Pine Bonsai** (2): Long needles, rugged bark\n",
    "- **Maple Bonsai** (3): Distinctive lobed leaves\n",
    "\n",
    "We'll track:\n",
    "- **Parameters**: Model configuration (n_estimators, etc.)\n",
    "- **Metrics**: Classification performance (accuracy, etc.)\n",
    "- **Artifacts**: The trained bonsai classifier model\n",
    "\n",
    "Check the MLflow UI at http://localhost:5001 to see your bonsai classification experiments! üå±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96a8720-eca0-4173-9ed5-a5976750862c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå± Bonsai Dataset created:\n",
      "Training samples: 240\n",
      "Test samples: 60\n",
      "Features: ['leaf_length_cm', 'leaf_width_cm', 'branch_thickness_mm', 'height_cm']\n",
      "Species classes: ['Juniper', 'Ficus', 'Pine', 'Maple']\n",
      "\n",
      "üìä Sample bonsai measurements:\n",
      "   leaf_length_cm  leaf_width_cm  branch_thickness_mm  height_cm species\n",
      "0        1.380904       1.188396             1.650313  19.065886   Ficus\n",
      "1        1.893503       1.425476             5.341917  30.000305   Maple\n",
      "2        2.007036       1.334003             7.963199  24.248633   Maple\n",
      "3        2.892563       1.966694             5.784386  14.109763   Maple\n",
      "4        3.342822       2.035872             5.564911   9.854393   Maple\n"
     ]
    }
   ],
   "source": [
    "import mlflow.sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a simulated bonsai dataset (replacing Iris for our bonsai classifier)\n",
    "# Features: leaf_length, leaf_width, branch_thickness, height\n",
    "X, y = make_classification(\n",
    "    n_samples=300,\n",
    "    n_features=4,\n",
    "    n_classes=4,\n",
    "    n_informative=4,\n",
    "    n_redundant=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Add realistic feature names and scaling for bonsai measurements\n",
    "feature_names = ['leaf_length_cm', 'leaf_width_cm', 'branch_thickness_mm', 'height_cm']\n",
    "bonsai_species = ['Juniper', 'Ficus', 'Pine', 'Maple']\n",
    "\n",
    "# Scale features to realistic bonsai measurements\n",
    "X[:, 0] = X[:, 0] * 0.5 + 2.0  # leaf_length: 1.5-2.5 cm\n",
    "X[:, 1] = X[:, 1] * 0.3 + 1.5  # leaf_width: 1.2-1.8 cm\n",
    "X[:, 2] = X[:, 2] * 2.0 + 5.0  # branch_thickness: 3-7 mm\n",
    "X[:, 3] = X[:, 3] * 10.0 + 25.0  # height: 15-35 cm\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "bonsai_df = pd.DataFrame(X, columns=feature_names)\n",
    "bonsai_df['species'] = [bonsai_species[i] for i in y]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"üå± Bonsai Dataset created:\")\n",
    "print(f\"Training samples: {X_train.shape[0]}\")\n",
    "print(f\"Test samples: {X_test.shape[0]}\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Species classes: {bonsai_species}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\nüìä Sample bonsai measurements:\")\n",
    "print(bonsai_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc2b01",
   "metadata": {},
   "source": [
    "# üÜï MLflow 3.3.1 Dataset Feature\n",
    "MLflow Datasets allow you to track, version, and reuse input data for your experiments. This ensures reproducibility and makes it easy to compare results across different runs.\n",
    "- **Track the exact data used for each run**\n",
    "- **Version datasets for auditability**\n",
    "- **Share and reuse datasets in future experiments**\n",
    "Let's log our bonsai dataset using MLflow's new Dataset API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067309aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Log the bonsai dataset using MLflow Datasets (v3.3.1+)\n",
    "import mlflow.data\n",
    "\n",
    "bonsai_df.to_csv(f\"bonsai_dataset_{date}.csv\", index=False)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    dataset = mlflow.data.from_pandas(\n",
    "        bonsai_df,\n",
    "        source=f\"bonsai_dataset_{date}.csv\",\n",
    "        name=\"bonsai_species_measurements\"\n",
    "    )\n",
    "    mlflow.log_input(dataset, context=\"training\")\n",
    "    print(\"‚úÖ Bonsai dataset logged as MLflow Dataset!\")\n",
    "    run_id = run.info.run_id\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c6cda93-8518-46f1-8c8c-53800636a243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Running multiple experiments for comparison...\n",
      "============================================================\n",
      "‚úÖ Bonsai dataset logged as MLflow Dataset!\n",
      "‚úÖ baseline_model: Accuracy=0.617, F1=0.621\n",
      "üèÉ View run baseline_model at: http://mlflow:5000/#/experiments/1/runs/6148af1389864d35921ebde8284c98df\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n",
      "‚úÖ Bonsai dataset logged as MLflow Dataset!\n",
      "‚úÖ balanced_model: Accuracy=0.750, F1=0.753\n",
      "üèÉ View run balanced_model at: http://mlflow:5000/#/experiments/1/runs/bbe13636b0bb4f3484026731cef86897\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n",
      "‚úÖ Bonsai dataset logged as MLflow Dataset!\n",
      "‚úÖ complex_model: Accuracy=0.767, F1=0.762\n",
      "üèÉ View run complex_model at: http://mlflow:5000/#/experiments/1/runs/f4d891f0d0174d9086da22ab32a60435\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n",
      "‚úÖ Bonsai dataset logged as MLflow Dataset!\n",
      "‚úÖ optimized_model: Accuracy=0.817, F1=0.817\n",
      "üèÉ View run optimized_model at: http://mlflow:5000/#/experiments/1/runs/de7169403e2243fca71c7e67af63e447\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/1\n",
      "\n",
      "üìä Experiment Summary:\n",
      "------------------------------------------------------------\n",
      "üèÜ optimized_model: 0.817 acc | 0.817 f1\n",
      "   üìù Optimized model based on previous results\n",
      "üèÜ complex_model: 0.767 acc | 0.762 f1\n",
      "   üìù More complex model for maximum performance\n",
      "üèÜ balanced_model: 0.750 acc | 0.753 f1\n",
      "   üìù Balanced model between complexity and performance\n",
      "üèÜ baseline_model: 0.617 acc | 0.621 f1\n",
      "   üìù Baseline model with conservative settings\n",
      "\n",
      "üåê Compare experiments in MLflow UI: http://localhost:5001\n",
      "üí° Use 'Compare' to view differences side by side!\n"
     ]
    }
   ],
   "source": [
    "# Experiments with different configurations to compare performance\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import mlflow.data\n",
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# First thing version our dataset\n",
    "bonsai_df.to_csv(f\"bonsai_dataset_{date}.csv\", index=False)\n",
    "\n",
    "dataset = mlflow.data.from_pandas(\n",
    "    bonsai_df,\n",
    "    source=f\"bonsai_dataset_{date}.csv\",\n",
    "    name=f\"bonsai_species_measurements_{date}\",\n",
    "    targets=\"species\" if \"species\" in bonsai_df.columns else None,\n",
    ")\n",
    "# Set up experiment for bonsai classification\n",
    "mlflow.set_experiment(\"Bonsai-Species-Classification\")\n",
    "\n",
    "# List of configurations to test\n",
    "experiment_configs = [\n",
    "    {\n",
    "        \"name\": \"baseline_model\",\n",
    "        \"n_estimators\": 50,\n",
    "        \"max_depth\": 3,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"description\": \"Baseline model with conservative settings\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"balanced_model\", \n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 5,\n",
    "        \"min_samples_split\": 3,\n",
    "        \"description\": \"Balanced model between complexity and performance\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"complex_model\",\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": 8,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"description\": \"More complex model for maximum performance\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"optimized_model\",\n",
    "        \"n_estimators\": 150,\n",
    "        \"max_depth\": 6,\n",
    "        \"min_samples_split\": 4,\n",
    "        \"description\": \"Optimized model based on previous results\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üß™ Running multiple experiments for comparison...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run experiments\n",
    "experiment_results = []\n",
    "\n",
    "for config in experiment_configs:\n",
    "    with mlflow.start_run(run_name=config[\"name\"]):\n",
    "\n",
    "        # Log the bonsai dataset using MLflow Datasets\n",
    "        mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "        \n",
    "        # Train model with specific configuration\n",
    "        bonsai_classifier = RandomForestClassifier(\n",
    "            n_estimators=config[\"n_estimators\"],\n",
    "            max_depth=config[\"max_depth\"],\n",
    "            min_samples_split=config[\"min_samples_split\"],\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "\n",
    "        bonsai_classifier.fit(X_train, y_train)\n",
    "        preds = bonsai_classifier.predict(X_test)\n",
    "        print(\"‚úÖ Bonsai dataset logged as MLflow Dataset!\")\n",
    "        \n",
    "        # Calculate detailed metrics\n",
    "        accuracy = accuracy_score(y_test, preds)\n",
    "        precision = precision_score(y_test, preds, average='weighted')\n",
    "        recall = recall_score(y_test, preds, average='weighted')\n",
    "        f1 = f1_score(y_test, preds, average='weighted')\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params({\n",
    "            \"n_estimators\": config[\"n_estimators\"],\n",
    "            \"max_depth\": config[\"max_depth\"],\n",
    "            \"min_samples_split\": config[\"min_samples_split\"],\n",
    "            \"model_type\": \"RandomForestClassifier\",\n",
    "            \"dataset\": \"Bonsai Species\",\n",
    "            \"n_species\": len(bonsai_species),\n",
    "            \"description\": config[\"description\"]\n",
    "        })\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "            \"test_samples\": len(y_test),\n",
    "            \"training_samples\": len(y_train)\n",
    "        })\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(\n",
    "            bonsai_classifier, \n",
    "            name=\"bonsai_classifier\",\n",
    "            signature=mlflow.models.infer_signature(X_train, y_train)\n",
    "        )\n",
    "        \n",
    "        # Log confusion matrix as artifact\n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        im = ax.imshow(cm, cmap='Blues')\n",
    "        ax.set_title('Confusion Matrix')\n",
    "        ax.set_xlabel('Predicted')\n",
    "        ax.set_ylabel('Actual')\n",
    "        plt.colorbar(im)\n",
    "        plt.xticks(np.arange(len(bonsai_species)), bonsai_species)\n",
    "        plt.yticks(np.arange(len(bonsai_species)), bonsai_species)\n",
    "        for i in range(len(bonsai_species)):\n",
    "            for j in range(len(bonsai_species)):\n",
    "                ax.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
    "        plt.tight_layout()\n",
    "        cm_path = f\"confusion_matrix_{config['name']}.png\"\n",
    "        plt.savefig(cm_path)\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(cm_path)\n",
    "        os.remove(cm_path)\n",
    "\n",
    "        # Log sample predictions as CSV artifact\n",
    "        sample_df = pd.DataFrame({\n",
    "            'actual': [bonsai_species[i] for i in y_test],\n",
    "            'predicted': [bonsai_species[i] for i in preds]\n",
    "        })\n",
    "        sample_path = f\"sample_predictions_{config['name']}.csv\"\n",
    "        sample_df.to_csv(sample_path, index=False)\n",
    "        mlflow.log_artifact(sample_path)\n",
    "        os.remove(sample_path)\n",
    "\n",
    "        # Save results for comparison\n",
    "        experiment_results.append({\n",
    "            \"name\": config[\"name\"],\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "            \"description\": config[\"description\"]\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ {config['name']}: Accuracy={accuracy:.3f}, F1={f1:.3f}\")\n",
    "\n",
    "print(\"\\nüìä Experiment Summary:\")\n",
    "print(\"-\" * 60)\n",
    "for result in sorted(experiment_results, key=lambda x: x['accuracy'], reverse=True):\n",
    "    print(f\"üèÜ {result['name']}: {result['accuracy']:.3f} acc | {result['f1_score']:.3f} f1\")\n",
    "    print(f\"   üìù {result['description']}\")\n",
    "\n",
    "print(f\"\\nüåê Compare experiments in MLflow UI: http://localhost:5001\")\n",
    "print(\"üí° Use 'Compare' to view differences side by side!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ddb4d-6c31-4034-b006-1066b0a46547",
   "metadata": {},
   "source": [
    "# üå± MLflow Model Registry and Experiment Comparison\n",
    "\n",
    "## Model Registry - Model Management\n",
    "The **MLflow Model Registry** is a centralized repository to manage the model lifecycle:\n",
    "\n",
    "### Main Features:\n",
    "- **üîÑ Versioning**: Each registered model receives a unique version\n",
    "- **üìã Stages**: None ‚Üí Staging ‚Üí Production ‚Üí Archived\n",
    "- **üè∑Ô∏è Tags and Annotations**: Custom metadata for organization\n",
    "- **üîç Lineage**: Tracking model origin (experiment/run)\n",
    "- **üöÄ Deploy**: Integration with deployment systems\n",
    "\n",
    "### Recommended Workflow:\n",
    "1. **Experiments**: Multiple runs to find the best model\n",
    "2. **Registration**: Register the best model in the registry\n",
    "3. **Staging**: Test model in staging environment\n",
    "4. **Production**: Promote after complete validation\n",
    "5. **Monitoring**: Track performance in production\n",
    "\n",
    "## Experiment Comparison\n",
    "Use comparison features for:\n",
    "- **üìä Side-by-side metrics**: Accuracy, F1-score, Precision, Recall\n",
    "- **‚öôÔ∏è Hyperparameters**: Compare different configurations\n",
    "- **üìà Visualizations**: Automatic performance charts\n",
    "- **üîÑ Reproducibility**: All details to reproduce results\n",
    "\n",
    "### MLflow Tip:\n",
    "Use `mlflow.autolog()` for automatic capture of metrics, parameters and artifacts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b85654-8662-4ca9-8950-63968ef900f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Bonsai-Species-Classifier-Production'.\n",
      "2025/09/04 19:56:09 WARNING mlflow.tracking._model_registry.fluent: Run with id de7169403e2243fca71c7e67af63e447 has no artifacts at artifact path 'bonsai_classifier', registering model based on models:/m-9eee6f7bc09949bf836c20e47831cee3 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÜ Best model found:\n",
      "   Run ID: de7169403e2243fca71c7e67af63e447\n",
      "   Accuracy: 0.817\n",
      "   F1-Score: 0.817\n",
      "   Configuration: {'n_estimators': '150', 'max_depth': '6', 'min_samples_split': '4', 'model_type': 'RandomForestClassifier', 'dataset': 'Bonsai Species', 'n_species': '4', 'description': 'Optimized model based on previous results'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 19:56:09 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Bonsai-Species-Classifier-Production, version 1\n",
      "Created version '1' of model 'Bonsai-Species-Classifier-Production'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Model registered successfully!\n",
      "üì¶ Name: Bonsai-Species-Classifier-Production\n",
      "üî¢ Version: 1\n",
      "üåê MLflow UI: http://localhost:5000/#/models/Bonsai-Species-Classifier-Production\n",
      "ÔøΩÔ∏è  Tags and description added to the model\n",
      "üö¶ Model version 1 transitioned to Staging.\n",
      "\n",
      "üìà Next steps:\n",
      "1. Review model in MLflow UI\n",
      "2. Test model in staging\n",
      "3. Promote to production when approved\n"
     ]
    }
   ],
   "source": [
    "# Select and register the best model based on experiments\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow.pyfunc\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Find the best run based on accuracy metric\n",
    "experiment = mlflow.get_experiment_by_name(\"Bonsai-Species-Classification\")\n",
    "best_run = client.search_runs(\n",
    "    experiment_ids=[experiment.experiment_id],\n",
    "    order_by=[\"metrics.accuracy DESC\"],\n",
    "    max_results=1\n",
    ")[0]\n",
    "\n",
    "print(f\"üèÜ Best model found:\")\n",
    "print(f\"   Run ID: {best_run.info.run_id}\")\n",
    "print(f\"   Accuracy: {best_run.data.metrics['accuracy']:.3f}\")\n",
    "print(f\"   F1-Score: {best_run.data.metrics['f1_score']:.3f}\")\n",
    "print(f\"   Configuration: {best_run.data.params}\")\n",
    "\n",
    "# Register the best model in the Model Registry\n",
    "model_name = \"Bonsai-Species-Classifier-Production\"\n",
    "model_uri = f\"runs:/{best_run.info.run_id}/bonsai_classifier\"  # Use correct artifact path\n",
    "\n",
    "try:\n",
    "    # Register new model version\n",
    "    model_version = mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=model_name\n",
    "    )\n",
    "    print(f\"\\n‚úÖ Model registered successfully!\")\n",
    "    print(f\"üì¶ Name: {model_name}\")\n",
    "    print(f\"üî¢ Version: {model_version.version}\")\n",
    "    print(f\"üåê MLflow UI: http://localhost:5000/#/models/{model_name}\")\n",
    "\n",
    "    # Add tags and annotations to the registered model\n",
    "    client.set_model_version_tag(\n",
    "        name=model_name,\n",
    "        version=model_version.version,\n",
    "        key=\"use_case\",\n",
    "        value=\"plant_ecommerce_classification\"\n",
    "    )\n",
    "    client.set_model_version_tag(\n",
    "        name=model_name,\n",
    "        version=model_version.version,\n",
    "        key=\"model_type\",\n",
    "        value=\"RandomForestClassifier\"\n",
    "    )\n",
    "    # Update description with detailed information\n",
    "    client.update_model_version(\n",
    "        name=model_name,\n",
    "        version=model_version.version,\n",
    "        description=f\"\"\"\n",
    "        üå≥ Bonsai Species Classifier for E-commerce\n",
    "\n",
    "        **Performance:**\n",
    "        - Accuracy: {best_run.data.metrics['accuracy']:.3f}\n",
    "        - Precision: {best_run.data.metrics['precision']:.3f}\n",
    "        - Recall: {best_run.data.metrics['recall']:.3f}\n",
    "        - F1-Score: {best_run.data.metrics['f1_score']:.3f}\n",
    "\n",
    "        **Configuration:**\n",
    "        - Estimators: {best_run.data.params['n_estimators']}\n",
    "        - Max Depth: {best_run.data.params['max_depth']}\n",
    "        - Min Samples Split: {best_run.data.params['min_samples_split']}\n",
    "\n",
    "        **Use Cases:**\n",
    "        - Automatic bonsai species identification\n",
    "        - Care recommendations based on species\n",
    "        - Purchase decision support for customers\n",
    "\n",
    "        **Classes:** Juniper (0), Ficus (1), Pine (2), Maple (3)\n",
    "        \"\"\"\n",
    "    )\n",
    "    print(f\"ÔøΩÔ∏è  Tags and description added to the model\")\n",
    "\n",
    "    # Transition model version to Staging (best practice)\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=model_version.version,\n",
    "        stage=\"Staging\"\n",
    "    )\n",
    "    print(f\"üö¶ Model version {model_version.version} transitioned to Staging.\")\n",
    "\n",
    "    # To promote to Production after validation:\n",
    "    # client.transition_model_version_stage(\n",
    "    #     name=model_name,\n",
    "    #     version=model_version.version,\n",
    "    #     stage=\"Production\"\n",
    "    # )\n",
    "    # print(f\"üöÄ Model version {model_version.version} promoted to Production.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error registering model: {e}\")\n",
    "    print(\"üí° Check if the MLflow server is running\")\n",
    "\n",
    "print(f\"\\nüìà Next steps:\")\n",
    "print(f\"1. Review model in MLflow UI\")\n",
    "print(f\"2. Test model in staging\")\n",
    "print(f\"3. Promote to production when approved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf5cd5",
   "metadata": {},
   "source": [
    "# MLflow 3.3.1: Experiments, Artifact Logging, and Model Registry Best Practices\n",
    "\n",
    "**Experiments & Artifact Logging**\n",
    "- Track multiple experiments (runs) with parameters, metrics, and artifacts.\n",
    "- Log artifacts (models, plots, files) using `mlflow.log_artifact()` or `mlflow.<flavor>.log_model()`.\n",
    "- Artifacts help reproduce results and compare runs.\n",
    "\n",
    "**Model Registry Workflow**\n",
    "- Register your best model with `mlflow.register_model(model_uri, name)`.\n",
    "- Registry supports model versioning and lifecycle stages: `None`, `Staging`, `Production`, `Archived`.\n",
    "- Use MLflow UI or `MlflowClient` to transition model versions:\n",
    "  - `client.transition_model_version_stage(name, version, stage=\"Staging\")`\n",
    "  - `client.transition_model_version_stage(name, version, stage=\"Production\")`\n",
    "\n",
    "**Identifying Staging/Production Versions**\n",
    "- Assign tags and descriptions to model versions for clarity.\n",
    "- Promote/demote versions between stages using UI or API.\n",
    "- Only one version should be in `Production` at a time for a given model.\n",
    "\n",
    "**Best Practices**\n",
    "- Always log relevant artifacts for each run.\n",
    "- Use clear naming and tagging for models and versions.\n",
    "- Automate stage transitions as part of your CI/CD pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8398b505",
   "metadata": {},
   "source": [
    "## üî¨ Test Model in Staging\n",
    "\n",
    "Before promoting a model to production, it's essential to validate its performance in a controlled staging environment. Here, we load the model from the MLflow registry (in the 'Staging' stage) and run predictions on new data. This step ensures the model meets quality standards and behaves as expected before serving real users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1aafce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: models:/Bonsai-Species-Classifier-Production/Staging\n",
      "Predicted class for first test sample: Maple\n"
     ]
    }
   ],
   "source": [
    "# Test model in staging\n",
    "from mlflow.pyfunc import load_model\n",
    "\n",
    "# Get the latest model version in staging\n",
    "model_name = \"Bonsai-Species-Classifier-Production\"\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "staging_versions = [v for v in client.get_latest_versions(model_name, stages=[\"Staging\"])]\n",
    "if staging_versions:\n",
    "    staging_model_uri = f\"models:/{model_name}/Staging\"\n",
    "    print(f\"Loading model from: {staging_model_uri}\")\n",
    "    model = load_model(staging_model_uri)\n",
    "    # Example prediction (using first test sample)\n",
    "    sample = X_test[0].reshape(1, -1)\n",
    "    pred = model.predict(sample)\n",
    "    print(f\"Predicted class for first test sample: {bonsai_species[pred[0]]}\")\n",
    "else:\n",
    "    print(\"No model in Staging stage found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc62b685",
   "metadata": {},
   "source": [
    "## üöÄ Promote Model to Production\n",
    "\n",
    "Once the model passes all tests in staging, it's ready to be promoted to production. This step updates the model's stage in the MLflow registry, making it available for real-world predictions. Production models should be monitored for performance and retrained as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d0f89e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Model version 1 promoted to Production.\n"
     ]
    }
   ],
   "source": [
    "# Promote model to production when approved\n",
    "model_name = \"Bonsai-Species-Classifier-Production\"\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()\n",
    "staging_versions = [v for v in client.get_latest_versions(model_name, stages=[\"Staging\"])]\n",
    "if staging_versions:\n",
    "    version = staging_versions[0].version\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=version,\n",
    "        stage=\"Production\"\n",
    "    )\n",
    "    print(f\"üöÄ Model version {version} promoted to Production.\")\n",
    "else:\n",
    "    print(\"No model in Staging stage to promote.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c143748",
   "metadata": {},
   "source": [
    "# üéì What Did We Learn?\n",
    "\n",
    "In this notebook, you:\n",
    "- Built and tracked a bonsai species classifier using MLflow\n",
    "- Logged parameters, metrics, and artifacts for reproducibility\n",
    "- Registered your model and managed its lifecycle (Staging ‚Üí Production)\n",
    "- Validated model performance before production deployment\n",
    "\n",
    "## üõ†Ô∏è Next Steps\n",
    "- **Monitor** your production model for drift and performance\n",
    "- **Automate** retraining and deployment with CI/CD pipelines\n",
    "- **Serve** your model via an API for real-time predictions\n",
    "- **Integrate** with business systems for end-to-end MLOps\n",
    "\n",
    "Explore MLflow's advanced features and try deploying your own models in a real project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e79802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction result: {'prediction': 3, 'species': 'Maple', 'confidence': 'high', 'care_recommendations': 'Needs partial shade, consistent moisture, protection from wind', 'input_features': {'leaf_length_cm': 5.2, 'leaf_width_cm': 3.1, 'branch_thickness_mm': 2.0, 'height_cm': 25.0}}\n"
     ]
    }
   ],
   "source": [
    "# Test the Bonsai Species Classification API\n",
    "import requests\n",
    "\n",
    "# Example input features: [leaf_length_cm, leaf_width_cm, branch_thickness_mm, height_cm]\n",
    "features = [5.2, 3.1, 2.0, 25.0]\n",
    "\n",
    "# API\n",
    "url = \"http://api:8080/predict\"\n",
    "payload = {\"features\": features}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, json=payload)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    print(\"Prediction result:\", result)\n",
    "except Exception as e:\n",
    "    print(f\"API call failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147852a-7b3b-412e-bd1b-e19f802e29ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
